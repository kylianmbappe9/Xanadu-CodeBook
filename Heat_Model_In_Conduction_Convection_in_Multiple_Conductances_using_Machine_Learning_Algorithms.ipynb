{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLcWupZWHV8eeYAOpyDelt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylianmbappe9/Xanadu-CodeBook/blob/main/Heat_Model_In_Conduction_Convection_in_Multiple_Conductances_using_Machine_Learning_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2FWc5L0A2zvV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def physics_model_3d(T, dx, dy, dz, dt, alpha=0.01):\n",
        "    d2T_dx2 = (np.roll(T, 1, axis=2) - 2 * T + np.roll(T, -1, axis=2)) / (dx**2)\n",
        "    d2T_dy2 = (np.roll(T, 1, axis=1) - 2 * T + np.roll(T, -1, axis=1)) / (dy**2)\n",
        "    d2T_dz2 = (np.roll(T, 1, axis=0) - 2 * T + np.roll(T, -1, axis=0)) / (dz**2)\n",
        "    T_new = T + alpha * dt * (d2T_dx2 + d2T_dy2 + d2T_dz2)\n",
        "    return T_new\n"
      ],
      "metadata": {
        "id": "S-jYJvZqF7UI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.InputLayer(input_shape=input_shape),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(np.prod(input_shape), activation='linear'),\n",
        "        layers.Reshape(input_shape)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "hdQBDoOFF9_f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs, initial_temperature, dx, dy, dz, dt, lambda_physics=1.0):\n",
        "    grid_size = initial_temperature.shape\n",
        "    physics_T = initial_temperature.copy()\n",
        "    generator = build_generator(grid_size)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            predicted_T = generator(np.expand_dims(physics_T, axis=0), training=True)[0]\n",
        "\n",
        "            # Data loss (MSE between predicted and actual temperature)\n",
        "            #MSE is mean squared error AND WE JUSt want to\n",
        "            #differentiate between the mean squared error of ML and PIML and ensure its smaller\n",
        "            actual_T = physics_model_3d(physics_T, dx, dy, dz, dt)\n",
        "            data_loss = tf.reduce_mean(tf.square(predicted_T - actual_T))\n",
        "\n",
        "            # Physics loss (checking if predicted_T satisfies the 3D heat equation)\n",
        "            d2T_dx2 = (tf.roll(predicted_T, 1, axis=2) - 2 * predicted_T + tf.roll(predicted_T, -1, axis=2)) / (dx**2)\n",
        "            d2T_dy2 = (tf.roll(predicted_T, 1, axis=1) - 2 * predicted_T + tf.roll(predicted_T, -1, axis=1)) / (dy**2)\n",
        "            d2T_dz2 = (tf.roll(predicted_T, 1, axis=0) - 2 * predicted_T + tf.roll(predicted_T, -1, axis=0)) / (dz**2)\n",
        "            physics_residual = tf.abs((predicted_T - actual_T) / dt - (d2T_dx2 + d2T_dy2 + d2T_dz2))\n",
        "            physics_loss = tf.reduce_mean(physics_residual)\n",
        "\n",
        "            # Total loss (ML loss + weighted physics loss)\n",
        "            total_loss = data_loss + lambda_physics * physics_loss\n",
        "\n",
        "        # Compute gradients and apply updates\n",
        "        grads = tape.gradient(total_loss, generator.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}, Data Loss: {data_loss.numpy()}, Physics Loss: {physics_loss.numpy()}, Total Loss: {total_loss.numpy()}\")\n",
        "\n",
        "        # Update the physics model temperature (real behavior)\n",
        "        physics_T = actual_T\n"
      ],
      "metadata": {
        "id": "o8Q9WoL1GA02"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_size = (50, 50, 50)  # 3D grid size\n",
        "dx, dy, dz = 1.0, 1.0, 1.0  # Spatial steps\n",
        "dt = 0.01  # Time step\n",
        "initial_temperature = np.zeros(grid_size)\n",
        "initial_temperature[25, 25, 25] = 100  # Hot spot in the center of the 3D grid"
      ],
      "metadata": {
        "id": "1aItVPr8GCn3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(epochs=1000, initial_temperature=initial_temperature, dx=dx, dy=dy, dz=dz, dt=dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkyu8JqUGEDX",
        "outputId": "d7d88f7a-acba-4972-ad56-5de50221780b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Data Loss: 0.07997702807188034, Physics Loss: 0.8112882375717163, Total Loss: 0.8912652730941772\n",
            "Epoch 100, Data Loss: 0.0707937553524971, Physics Loss: 0.095188669860363, Total Loss: 0.1659824252128601\n",
            "Epoch 200, Data Loss: 0.06284353882074356, Physics Loss: 0.09494806826114655, Total Loss: 0.1577916145324707\n",
            "Epoch 300, Data Loss: 0.05588946491479874, Physics Loss: 0.09057974815368652, Total Loss: 0.14646920561790466\n",
            "Epoch 400, Data Loss: 0.049794040620326996, Physics Loss: 0.09212061017751694, Total Loss: 0.14191465079784393\n",
            "Epoch 500, Data Loss: 0.04443962872028351, Physics Loss: 0.08815043419599533, Total Loss: 0.13259005546569824\n",
            "Epoch 600, Data Loss: 0.03972594812512398, Physics Loss: 0.08646100759506226, Total Loss: 0.12618695199489594\n",
            "Epoch 700, Data Loss: 0.03556735813617706, Physics Loss: 0.08487284183502197, Total Loss: 0.12044019997119904\n",
            "Epoch 800, Data Loss: 0.0318906232714653, Physics Loss: 0.08334868401288986, Total Loss: 0.11523930728435516\n",
            "Epoch 900, Data Loss: 0.028633011505007744, Physics Loss: 0.08158291131258011, Total Loss: 0.110215924680233\n"
          ]
        }
      ]
    }
  ]
}